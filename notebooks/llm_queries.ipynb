{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Queries\n",
    "Bill Xia<br>\n",
    "April 18, 2025\n",
    "\n",
    "**Purpose:** A space to learn how to perform Neo4j queries using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "from json import load\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "User {username: STRING, is_private: BOOLEAN}\n",
      "Pin {pin_id: INTEGER, caption: STRING, url: STRING}\n",
      "Board {is_private: BOOLEAN, board_id: INTEGER, board_name: STRING}\n",
      "ShareEvent {share_id: INTEGER, share_time: DATE_TIME}\n",
      "Group {group_id: INTEGER, permissions: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:User)-[:CREATED]->(:Pin)\n",
      "(:User)-[:CREATED]->(:Board)\n",
      "(:User)-[:CREATED]->(:Group)\n",
      "(:User)-[:FOLLOWS]->(:User)\n",
      "(:User)-[:FOLLOWS]->(:Board)\n",
      "(:User)-[:BLOCKS]->(:User)\n",
      "(:User)-[:SHARES]->(:ShareEvent)\n",
      "(:User)-[:SAVES]->(:Pin)\n",
      "(:Board)-[:CONTAINS]->(:Pin)\n",
      "(:ShareEvent)-[:DELIVERS]->(:Pin)\n",
      "(:ShareEvent)-[:HAS_RECIPIENT]->(:User)\n",
      "(:Group)-[:HAS_MEMBER]->(:User)\n",
      "(:Group)-[:CAN_ACCESS]->(:Board)\n"
     ]
    }
   ],
   "source": [
    "# Load graph.\n",
    "with open('../../../Documents/API_Keys/Neo4j-Instance01.json') as fp:\n",
    "    credentials = load(fp)\n",
    "assert credentials['NEO4J_URI'].startswith(\"neo4j+ssc://\")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url      = credentials['NEO4J_URI'],\n",
    "    username = credentials['NEO4J_USERNAME'],\n",
    "    password = credentials['NEO4J_PASSWORD']\n",
    ")\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/59p675nx1ylcm5hhmc_djrp80000gn/T/ipykernel_82080/3340281701.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=model_name)\n"
     ]
    }
   ],
   "source": [
    "# Load LLM.\n",
    "model_name = 'llama3.2:latest'\n",
    "llm = Ollama(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QA chain.\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm, graph=graph, verbose=True, allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/59p675nx1ylcm5hhmc_djrp80000gn/T/ipykernel_82080/3921008535.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (u:User {username: 'Cindy'})-[:FOLLOWS]-(f:User) RETURN COUNT(f)\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'COUNT(f)': 3}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "# Running the chain.\n",
    "query = \"How many followers does Cindy have?\"\n",
    "response = chain.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "We've figured out how to query the database using an LLM as an intermediary.\n",
    "Now we need to tune our prompt so that the LLM (which in this case, is pretty\n",
    "weak) can understand what gets returned by the graph query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Task: Generate Cypher code to query to a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\"\"\"\n",
    "full_prompt = PromptTemplate(\n",
    "    input_variables = ['schema', 'question'],\n",
    "    template        = prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chain.\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm,\n",
    "    graph                    = graph,\n",
    "    verbose                  = True,\n",
    "    cypher_prompt            = full_prompt,\n",
    "    allow_dangerous_requests = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Pin {pin_id: 0})-[:CREATED]->(u:User) RETURN u.username\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': 'Who created pin 0?', 'result': \"I don't have enough information to provide an answer.\"}\n"
     ]
    }
   ],
   "source": [
    "# Running the chain.\n",
    "query    = \"Who created pin 0?\"\n",
    "response = chain.invoke({\"query\": query})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGRAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
